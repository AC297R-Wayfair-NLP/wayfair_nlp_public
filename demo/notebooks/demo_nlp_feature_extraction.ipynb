{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using small toy (fake) data, this notebook demonstrates how to use NLP extractor classes to obtain desired features (e.g., sentiment, returnability, topic scores) from customer reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure environment\n",
    "from os import path\n",
    "CURR_PATH = path.abspath(\"__file__\") # Full path to current script\n",
    "ROOT_PATH = path.dirname(path.dirname(path.dirname(CURR_PATH)))\n",
    "import sys; sys.path.insert(0, ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/alex/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.features import Sentiment, Returnability, Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s first load and check the toy data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "products_df = pd.read_csv(path.join(ROOT_PATH, \"demo\", \"data\", \"toydata_products.csv\"))\n",
    "reviews_df = pd.read_csv(path.join(ROOT_PATH, \"demo\", \"data\", \"toydata_reviews.csv\"))\n",
    "\n",
    "products_df = products_df[products_df['year']==2017].drop('year', 1)\n",
    "reviews_df = reviews_df.drop('year', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wfsku</th>\n",
       "      <th>mkcname</th>\n",
       "      <th>avgweight</th>\n",
       "      <th>returnratescaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Bath</td>\n",
       "      <td>29.071028</td>\n",
       "      <td>0.443155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>Bath</td>\n",
       "      <td>32.733974</td>\n",
       "      <td>0.326510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>Bedroom</td>\n",
       "      <td>26.795903</td>\n",
       "      <td>0.703419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>Bedroom</td>\n",
       "      <td>37.564827</td>\n",
       "      <td>0.013095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>Lighting</td>\n",
       "      <td>29.051481</td>\n",
       "      <td>0.050202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>Lighting</td>\n",
       "      <td>31.353412</td>\n",
       "      <td>0.813216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>Bath</td>\n",
       "      <td>28.813357</td>\n",
       "      <td>0.758053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H</td>\n",
       "      <td>Bedroom</td>\n",
       "      <td>31.003479</td>\n",
       "      <td>0.769882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I</td>\n",
       "      <td>Bath</td>\n",
       "      <td>35.247619</td>\n",
       "      <td>0.464246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>J</td>\n",
       "      <td>Lighting</td>\n",
       "      <td>35.580414</td>\n",
       "      <td>0.169323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  wfsku   mkcname  avgweight  returnratescaled\n",
       "0     A      Bath  29.071028          0.443155\n",
       "1     B      Bath  32.733974          0.326510\n",
       "2     C   Bedroom  26.795903          0.703419\n",
       "3     D   Bedroom  37.564827          0.013095\n",
       "4     E  Lighting  29.051481          0.050202\n",
       "5     F  Lighting  31.353412          0.813216\n",
       "6     G      Bath  28.813357          0.758053\n",
       "7     H   Bedroom  31.003479          0.769882\n",
       "8     I      Bath  35.247619          0.464246\n",
       "9     J  Lighting  35.580414          0.169323"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview product-level data\n",
    "products_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rvprcomments</th>\n",
       "      <th>wasreturned</th>\n",
       "      <th>wfsku</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely thrilled about these.  They are so ...</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They were nice but too big for my area that I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I returned this item the item was not the prob...</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Awful! Sending back. Doesn’t even look close t...</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There was no replacement bulb as advertised. W...</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Chair is gorgeous and was easy to put together...</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>love this chair!! its nice looking and comfy</td>\n",
       "      <td>0</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Wayfair gave a great price, great shipping and...</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Perfect size for pasta or salad. Classic style...</td>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Absolutely beautiful furniture!</td>\n",
       "      <td>0</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          rvprcomments  wasreturned wfsku\n",
       "0    Absolutely thrilled about these.  They are so ...            1     A\n",
       "1    They were nice but too big for my area that I ...            1     B\n",
       "2    I returned this item the item was not the prob...            1     C\n",
       "3    Awful! Sending back. Doesn’t even look close t...            1     D\n",
       "4    There was no replacement bulb as advertised. W...            1     E\n",
       "..                                                 ...          ...   ...\n",
       "995  Chair is gorgeous and was easy to put together...            0     F\n",
       "996       love this chair!! its nice looking and comfy            0     G\n",
       "997  Wayfair gave a great price, great shipping and...            0     H\n",
       "998  Perfect size for pasta or salad. Classic style...            0     I\n",
       "999                    Absolutely beautiful furniture!            0     J\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview review-level data\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to extract NLP features from texts in `reviews_df` and merge their product-level averages into `products_df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Extracting NLP Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sentiment` class extracts sentiment-related features (e.g., negativity) using pre-trained models in `nltk` and `textblob` packages. Hence, it does not need separate training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/sangyoonpark/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Initiate model\n",
    "sentiment = Sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "sentiment_features = sentiment.extract(reviews_df['rvprcomments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.9067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.636667</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.9634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.8217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.635000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.9450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.5719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.6689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subjectivity    neg    neu    pos  compound\n",
       "0        0.816667  0.000  0.614  0.386    0.9067\n",
       "1        0.550000  0.000  0.863  0.137    0.2263\n",
       "2        0.250000  0.113  0.771  0.116    0.0150\n",
       "3        0.636667  0.230  0.770  0.000   -0.5093\n",
       "4        0.700000  0.059  0.941  0.000   -0.2960\n",
       "..            ...    ...    ...    ...       ...\n",
       "995      0.533333  0.000  0.619  0.381    0.9634\n",
       "996      0.800000  0.000  0.442  0.558    0.8217\n",
       "997      0.635000  0.000  0.420  0.580    0.9450\n",
       "998      0.583333  0.000  0.730  0.270    0.5719\n",
       "999      1.000000  0.000  0.308  0.692    0.6689\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check result\n",
    "sentiment_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge extracted features into original data\n",
    "reviews_df = pd.concat([reviews_df, sentiment_features], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Returnability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Returnability` class extracts features related to product return using a BERT-based classifier for whether a review resulted in a product return or not. Therefore, it needs to be first trained on labeled text data (i.e. reviews resulting in return vs. no return)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead\n",
      "Work may take extremely long time; consider using GPU\n"
     ]
    }
   ],
   "source": [
    "# Initiate model\n",
    "BERT_returnability = Returnability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the BERT-based model takes a long time (especially if GPU is not available), so we often do training on a subset of the given data. Let’s do that here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epoch took: 0:00:35\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "  Average validation loss: 0.69\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "  Average validation loss: 0.69\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.68\n",
      "  Training epoch took: 0:00:33\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "  Average validation loss: 0.69\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:01:48 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "# Subset data\n",
    "reviews_df_sub = reviews_df.sample(n=100) # 10% of toy data\n",
    "\n",
    "# Train model\n",
    "BERT_returnability.train(\n",
    "    reviews=reviews_df_sub['rvprcomments'],\n",
    "    labels=reviews_df_sub['wasreturned'],\n",
    "    save_filename=path.join(ROOT_PATH, \"demo\", \"models\", \"toymodel_returnability.pt\") # Save trained model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained/validated over 3 epochs and the best one (i.e. model with the lowest average validation loss) is saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model has been trained and saved, let’s load it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load previously trained model weights\n",
    "BERT_returnability.load_model(path.join(ROOT_PATH, \"demo\", \"models\", \"toymodel_returnability.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use a different pre-trained model to perform feature extraction. For instance, the following loads the model trained on the entire review data from 2017:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model trained on entire review data from 2017\n",
    "# BERT_returnability.load_model(path.join(ROOT_PATH, \"models\", \"BERT_classifier_weights_sprint8.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the loaded model to extract features related to product return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting features...\n"
     ]
    }
   ],
   "source": [
    "# Extract features (from entire toy data)\n",
    "returnability_features = BERT_returnability.extract(reviews_df['rvprcomments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb1</th>\n",
       "      <th>emb2</th>\n",
       "      <th>emb3</th>\n",
       "      <th>emb4</th>\n",
       "      <th>emb5</th>\n",
       "      <th>emb6</th>\n",
       "      <th>emb7</th>\n",
       "      <th>emb8</th>\n",
       "      <th>emb9</th>\n",
       "      <th>emb10</th>\n",
       "      <th>emb11</th>\n",
       "      <th>emb12</th>\n",
       "      <th>emb13</th>\n",
       "      <th>emb14</th>\n",
       "      <th>emb15</th>\n",
       "      <th>emb16</th>\n",
       "      <th>p_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.085738</td>\n",
       "      <td>0.257699</td>\n",
       "      <td>0.118066</td>\n",
       "      <td>0.013044</td>\n",
       "      <td>-0.124014</td>\n",
       "      <td>-0.136310</td>\n",
       "      <td>0.043116</td>\n",
       "      <td>0.283141</td>\n",
       "      <td>-0.122666</td>\n",
       "      <td>-0.165492</td>\n",
       "      <td>0.191405</td>\n",
       "      <td>-0.088334</td>\n",
       "      <td>0.068480</td>\n",
       "      <td>-0.079817</td>\n",
       "      <td>0.051973</td>\n",
       "      <td>-0.180668</td>\n",
       "      <td>0.475461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065253</td>\n",
       "      <td>0.037195</td>\n",
       "      <td>0.146367</td>\n",
       "      <td>-0.076044</td>\n",
       "      <td>-0.256372</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>-0.108024</td>\n",
       "      <td>0.233402</td>\n",
       "      <td>-0.099681</td>\n",
       "      <td>0.020216</td>\n",
       "      <td>-0.073740</td>\n",
       "      <td>-0.107011</td>\n",
       "      <td>-0.034351</td>\n",
       "      <td>-0.138147</td>\n",
       "      <td>-0.023599</td>\n",
       "      <td>0.177158</td>\n",
       "      <td>0.505305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.084194</td>\n",
       "      <td>0.102908</td>\n",
       "      <td>0.156051</td>\n",
       "      <td>-0.095641</td>\n",
       "      <td>-0.102037</td>\n",
       "      <td>-0.086480</td>\n",
       "      <td>-0.023378</td>\n",
       "      <td>0.256139</td>\n",
       "      <td>-0.142111</td>\n",
       "      <td>-0.042361</td>\n",
       "      <td>0.081371</td>\n",
       "      <td>-0.101391</td>\n",
       "      <td>0.019372</td>\n",
       "      <td>-0.173496</td>\n",
       "      <td>0.020558</td>\n",
       "      <td>0.042286</td>\n",
       "      <td>0.492520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.133768</td>\n",
       "      <td>0.234132</td>\n",
       "      <td>0.087523</td>\n",
       "      <td>0.022394</td>\n",
       "      <td>-0.110837</td>\n",
       "      <td>-0.161413</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.284745</td>\n",
       "      <td>-0.078459</td>\n",
       "      <td>-0.184026</td>\n",
       "      <td>0.184995</td>\n",
       "      <td>-0.074023</td>\n",
       "      <td>0.076958</td>\n",
       "      <td>-0.044890</td>\n",
       "      <td>0.043529</td>\n",
       "      <td>-0.230942</td>\n",
       "      <td>0.475055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062233</td>\n",
       "      <td>0.165933</td>\n",
       "      <td>0.119340</td>\n",
       "      <td>-0.054423</td>\n",
       "      <td>-0.090893</td>\n",
       "      <td>-0.155029</td>\n",
       "      <td>0.034449</td>\n",
       "      <td>0.192151</td>\n",
       "      <td>-0.072766</td>\n",
       "      <td>-0.179385</td>\n",
       "      <td>0.148082</td>\n",
       "      <td>-0.049794</td>\n",
       "      <td>0.053612</td>\n",
       "      <td>-0.065891</td>\n",
       "      <td>0.035864</td>\n",
       "      <td>-0.131583</td>\n",
       "      <td>0.488051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.076263</td>\n",
       "      <td>0.167665</td>\n",
       "      <td>0.123643</td>\n",
       "      <td>-0.069697</td>\n",
       "      <td>-0.114485</td>\n",
       "      <td>-0.138100</td>\n",
       "      <td>0.036304</td>\n",
       "      <td>0.234786</td>\n",
       "      <td>-0.102340</td>\n",
       "      <td>-0.204039</td>\n",
       "      <td>0.187579</td>\n",
       "      <td>-0.062094</td>\n",
       "      <td>0.075429</td>\n",
       "      <td>-0.064454</td>\n",
       "      <td>0.104489</td>\n",
       "      <td>-0.150888</td>\n",
       "      <td>0.480893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.066437</td>\n",
       "      <td>0.106028</td>\n",
       "      <td>0.196471</td>\n",
       "      <td>-0.078311</td>\n",
       "      <td>-0.142841</td>\n",
       "      <td>-0.043661</td>\n",
       "      <td>-0.044618</td>\n",
       "      <td>0.263376</td>\n",
       "      <td>-0.104600</td>\n",
       "      <td>-0.060075</td>\n",
       "      <td>0.101862</td>\n",
       "      <td>-0.143819</td>\n",
       "      <td>0.035562</td>\n",
       "      <td>-0.196204</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.131481</td>\n",
       "      <td>0.497815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.071167</td>\n",
       "      <td>0.222655</td>\n",
       "      <td>0.138505</td>\n",
       "      <td>-0.026557</td>\n",
       "      <td>-0.108133</td>\n",
       "      <td>-0.112422</td>\n",
       "      <td>0.084748</td>\n",
       "      <td>0.286177</td>\n",
       "      <td>-0.116125</td>\n",
       "      <td>-0.131257</td>\n",
       "      <td>0.158168</td>\n",
       "      <td>-0.089275</td>\n",
       "      <td>0.036126</td>\n",
       "      <td>-0.113423</td>\n",
       "      <td>0.012092</td>\n",
       "      <td>-0.086477</td>\n",
       "      <td>0.481502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.100210</td>\n",
       "      <td>0.262722</td>\n",
       "      <td>0.131102</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>-0.089444</td>\n",
       "      <td>-0.146816</td>\n",
       "      <td>0.029026</td>\n",
       "      <td>0.298695</td>\n",
       "      <td>-0.088645</td>\n",
       "      <td>-0.148253</td>\n",
       "      <td>0.215767</td>\n",
       "      <td>-0.088470</td>\n",
       "      <td>0.066891</td>\n",
       "      <td>-0.110652</td>\n",
       "      <td>0.031237</td>\n",
       "      <td>-0.178992</td>\n",
       "      <td>0.475455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.043368</td>\n",
       "      <td>0.121975</td>\n",
       "      <td>0.193007</td>\n",
       "      <td>-0.039384</td>\n",
       "      <td>-0.130617</td>\n",
       "      <td>-0.074361</td>\n",
       "      <td>-0.039058</td>\n",
       "      <td>0.268511</td>\n",
       "      <td>-0.151731</td>\n",
       "      <td>-0.045169</td>\n",
       "      <td>0.117063</td>\n",
       "      <td>-0.147402</td>\n",
       "      <td>-0.014763</td>\n",
       "      <td>-0.190532</td>\n",
       "      <td>0.012395</td>\n",
       "      <td>0.088169</td>\n",
       "      <td>0.494958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         emb1      emb2      emb3      emb4      emb5      emb6      emb7  \\\n",
       "0    0.085738  0.257699  0.118066  0.013044 -0.124014 -0.136310  0.043116   \n",
       "1    0.065253  0.037195  0.146367 -0.076044 -0.256372  0.002775 -0.108024   \n",
       "2    0.084194  0.102908  0.156051 -0.095641 -0.102037 -0.086480 -0.023378   \n",
       "3    0.133768  0.234132  0.087523  0.022394 -0.110837 -0.161413  0.006956   \n",
       "4    0.062233  0.165933  0.119340 -0.054423 -0.090893 -0.155029  0.034449   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  0.076263  0.167665  0.123643 -0.069697 -0.114485 -0.138100  0.036304   \n",
       "996  0.066437  0.106028  0.196471 -0.078311 -0.142841 -0.043661 -0.044618   \n",
       "997  0.071167  0.222655  0.138505 -0.026557 -0.108133 -0.112422  0.084748   \n",
       "998  0.100210  0.262722  0.131102  0.018450 -0.089444 -0.146816  0.029026   \n",
       "999  0.043368  0.121975  0.193007 -0.039384 -0.130617 -0.074361 -0.039058   \n",
       "\n",
       "         emb8      emb9     emb10     emb11     emb12     emb13     emb14  \\\n",
       "0    0.283141 -0.122666 -0.165492  0.191405 -0.088334  0.068480 -0.079817   \n",
       "1    0.233402 -0.099681  0.020216 -0.073740 -0.107011 -0.034351 -0.138147   \n",
       "2    0.256139 -0.142111 -0.042361  0.081371 -0.101391  0.019372 -0.173496   \n",
       "3    0.284745 -0.078459 -0.184026  0.184995 -0.074023  0.076958 -0.044890   \n",
       "4    0.192151 -0.072766 -0.179385  0.148082 -0.049794  0.053612 -0.065891   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  0.234786 -0.102340 -0.204039  0.187579 -0.062094  0.075429 -0.064454   \n",
       "996  0.263376 -0.104600 -0.060075  0.101862 -0.143819  0.035562 -0.196204   \n",
       "997  0.286177 -0.116125 -0.131257  0.158168 -0.089275  0.036126 -0.113423   \n",
       "998  0.298695 -0.088645 -0.148253  0.215767 -0.088470  0.066891 -0.110652   \n",
       "999  0.268511 -0.151731 -0.045169  0.117063 -0.147402 -0.014763 -0.190532   \n",
       "\n",
       "        emb15     emb16  p_return  \n",
       "0    0.051973 -0.180668  0.475461  \n",
       "1   -0.023599  0.177158  0.505305  \n",
       "2    0.020558  0.042286  0.492520  \n",
       "3    0.043529 -0.230942  0.475055  \n",
       "4    0.035864 -0.131583  0.488051  \n",
       "..        ...       ...       ...  \n",
       "995  0.104489 -0.150888  0.480893  \n",
       "996  0.005051  0.131481  0.497815  \n",
       "997  0.012092 -0.086477  0.481502  \n",
       "998  0.031237 -0.178992  0.475455  \n",
       "999  0.012395  0.088169  0.494958  \n",
       "\n",
       "[1000 rows x 17 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check result\n",
    "returnability_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge extracted features into original data\n",
    "reviews_df = pd.concat([reviews_df, returnability_features], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Topics` class builds an LDA language model that identifies a set of topics commonly present across the given text data. This model can then be used to score a given text on the pre-identified topics. Therefore, it involves unsupervised training on the target text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sangyoonpark/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Initiate model\n",
    "topics = Topics(20) # Obtain 20 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Preprocessing----\n",
      "strip_newline...\n",
      "sent to words ...\n",
      "remove stop words...\n",
      "lemmatization...\n",
      "0\n",
      "dictionary...\n",
      "filter...\n",
      "compactify...\n",
      "bag of word\n",
      "Training Completed. The modeling process took 0.38419293562571205 minutes\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "topics.train(\n",
    "    reviews=reviews_df['rvprcomments'],\n",
    "    save_filename=path.join(ROOT_PATH, \"demo\", \"models\", \"toymodel_topics\") # Save trained model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Model loaded to disk----\n"
     ]
    }
   ],
   "source": [
    "# Load previously trained model\n",
    "topics.load_model(path.join(ROOT_PATH, \"demo\", \"models\", \"toymodel_topics\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use a different pre-trained model to perform feature extraction. For instance, the following loads the model trained on the entire review data from 2017:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model trained on entire review data from 2017\n",
    "# topics.load_model(path.join(ROOT_PATH, \"models\", \"topic_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the loaded model to extract topic scores for each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Topic Score Extracted----\n"
     ]
    }
   ],
   "source": [
    "topic_features = topics.extract(reviews=reviews_df['rvprcomments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.262499</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic_0   topic_1   topic_2   topic_3   topic_4   topic_5   topic_6  \\\n",
       "0    0.012500  0.262500  0.012500  0.012500  0.012500  0.262500  0.012500   \n",
       "1    0.016667  0.016667  0.016667  0.016667  0.016667  0.016667  0.350000   \n",
       "2    0.016667  0.016667  0.016667  0.016667  0.016667  0.016667  0.016667   \n",
       "3    0.025000  0.025000  0.025000  0.025000  0.025000  0.025000  0.025000   \n",
       "4    0.016667  0.016667  0.016667  0.016667  0.016667  0.016667  0.016667   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  0.010000  0.210000  0.010000  0.010000  0.010000  0.010000  0.010000   \n",
       "996  0.016667  0.016667  0.016667  0.016667  0.016667  0.016667  0.350000   \n",
       "997  0.010000  0.010000  0.010000  0.010000  0.010000  0.610000  0.210000   \n",
       "998  0.025000  0.025000  0.025000  0.025000  0.025000  0.025000  0.025000   \n",
       "999  0.025000  0.025000  0.025000  0.025000  0.025000  0.025000  0.025000   \n",
       "\n",
       "      topic_7   topic_8   topic_9  topic_10  topic_11  topic_12  topic_13  \\\n",
       "0    0.012500  0.012500  0.012500  0.012500  0.012500  0.012500  0.012500   \n",
       "1    0.016667  0.016667  0.016667  0.016667  0.016667  0.016667  0.016667   \n",
       "2    0.016667  0.016667  0.016667  0.016667  0.016667  0.016667  0.016667   \n",
       "3    0.025000  0.025000  0.025000  0.025000  0.025000  0.025000  0.025000   \n",
       "4    0.016667  0.016667  0.016667  0.016667  0.016667  0.016667  0.683333   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "995  0.010000  0.010000  0.210000  0.010000  0.010000  0.010000  0.010000   \n",
       "996  0.016667  0.016667  0.016667  0.016667  0.016667  0.016667  0.016667   \n",
       "997  0.010000  0.010000  0.010000  0.010000  0.010000  0.010000  0.010000   \n",
       "998  0.025000  0.525000  0.025000  0.025000  0.025000  0.025000  0.025000   \n",
       "999  0.025000  0.025000  0.025000  0.025000  0.525000  0.025000  0.025000   \n",
       "\n",
       "     topic_14  topic_15  topic_16  topic_17  topic_18  topic_19  \n",
       "0    0.012500  0.012500  0.012500  0.012500  0.262499  0.012500  \n",
       "1    0.016667  0.016667  0.350000  0.016667  0.016667  0.016667  \n",
       "2    0.350000  0.016667  0.350000  0.016667  0.016667  0.016667  \n",
       "3    0.025000  0.525000  0.025000  0.025000  0.025000  0.025000  \n",
       "4    0.016667  0.016667  0.016667  0.016667  0.016667  0.016667  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "995  0.010000  0.010000  0.010000  0.010000  0.010000  0.410000  \n",
       "996  0.016667  0.350000  0.016667  0.016667  0.016667  0.016667  \n",
       "997  0.010000  0.010000  0.010000  0.010000  0.010000  0.010000  \n",
       "998  0.025000  0.025000  0.025000  0.025000  0.025000  0.025000  \n",
       "999  0.025000  0.025000  0.025000  0.025000  0.025000  0.025000  \n",
       "\n",
       "[1000 rows x 20 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check result\n",
    "topic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge extracted features into original data\n",
    "reviews_df = pd.concat([reviews_df, topic_features], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Merging NLP Features into Product-Level Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all NLP features have been extracted, we can combine, aggregate, and merge them into the product-level data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify relevant columns in review-level data\n",
    "nlp_feature_cols = (\n",
    "    list(sentiment_features.columns) + \n",
    "    list(returnability_features.columns) + \n",
    "    list(topic_features.columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate up to product level\n",
    "nlp_features_product_level = reviews_df[['wfsku'] + nlp_feature_cols].groupby('wfsku').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge NLP features into product-level data\n",
    "products_df = products_df.merge(nlp_features_product_level, on='wfsku', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wfsku</th>\n",
       "      <th>mkcname</th>\n",
       "      <th>avgweight</th>\n",
       "      <th>returnratescaled</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>emb1</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "      <th>topic_15</th>\n",
       "      <th>topic_16</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Lighting</td>\n",
       "      <td>28.414403</td>\n",
       "      <td>0.593681</td>\n",
       "      <td>0.603041</td>\n",
       "      <td>0.03527</td>\n",
       "      <td>0.66913</td>\n",
       "      <td>0.29563</td>\n",
       "      <td>0.452125</td>\n",
       "      <td>0.070353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030215</td>\n",
       "      <td>0.055562</td>\n",
       "      <td>0.020465</td>\n",
       "      <td>0.028380</td>\n",
       "      <td>0.049465</td>\n",
       "      <td>0.078697</td>\n",
       "      <td>0.043955</td>\n",
       "      <td>0.053008</td>\n",
       "      <td>0.063191</td>\n",
       "      <td>0.052206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>Rugs</td>\n",
       "      <td>36.619338</td>\n",
       "      <td>0.065961</td>\n",
       "      <td>0.671528</td>\n",
       "      <td>0.04283</td>\n",
       "      <td>0.59847</td>\n",
       "      <td>0.35869</td>\n",
       "      <td>0.443316</td>\n",
       "      <td>0.076775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032076</td>\n",
       "      <td>0.037353</td>\n",
       "      <td>0.022174</td>\n",
       "      <td>0.026493</td>\n",
       "      <td>0.050864</td>\n",
       "      <td>0.106854</td>\n",
       "      <td>0.046019</td>\n",
       "      <td>0.044543</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.042712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>Tabletop</td>\n",
       "      <td>33.790857</td>\n",
       "      <td>0.120171</td>\n",
       "      <td>0.650995</td>\n",
       "      <td>0.04503</td>\n",
       "      <td>0.62919</td>\n",
       "      <td>0.32579</td>\n",
       "      <td>0.501917</td>\n",
       "      <td>0.072777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037819</td>\n",
       "      <td>0.032704</td>\n",
       "      <td>0.019410</td>\n",
       "      <td>0.052709</td>\n",
       "      <td>0.048334</td>\n",
       "      <td>0.079482</td>\n",
       "      <td>0.043561</td>\n",
       "      <td>0.052390</td>\n",
       "      <td>0.062868</td>\n",
       "      <td>0.056888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>Bedroom</td>\n",
       "      <td>32.060588</td>\n",
       "      <td>0.640660</td>\n",
       "      <td>0.596602</td>\n",
       "      <td>0.03180</td>\n",
       "      <td>0.65842</td>\n",
       "      <td>0.30977</td>\n",
       "      <td>0.453621</td>\n",
       "      <td>0.072893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034913</td>\n",
       "      <td>0.064193</td>\n",
       "      <td>0.023080</td>\n",
       "      <td>0.037382</td>\n",
       "      <td>0.047633</td>\n",
       "      <td>0.093049</td>\n",
       "      <td>0.045611</td>\n",
       "      <td>0.042580</td>\n",
       "      <td>0.058763</td>\n",
       "      <td>0.045817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>25.741503</td>\n",
       "      <td>0.476572</td>\n",
       "      <td>0.634164</td>\n",
       "      <td>0.03968</td>\n",
       "      <td>0.62331</td>\n",
       "      <td>0.33700</td>\n",
       "      <td>0.465525</td>\n",
       "      <td>0.078262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044107</td>\n",
       "      <td>0.042934</td>\n",
       "      <td>0.019172</td>\n",
       "      <td>0.056636</td>\n",
       "      <td>0.043017</td>\n",
       "      <td>0.098722</td>\n",
       "      <td>0.040517</td>\n",
       "      <td>0.051430</td>\n",
       "      <td>0.039114</td>\n",
       "      <td>0.049712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>Window</td>\n",
       "      <td>26.438588</td>\n",
       "      <td>0.835132</td>\n",
       "      <td>0.619593</td>\n",
       "      <td>0.03165</td>\n",
       "      <td>0.62760</td>\n",
       "      <td>0.34071</td>\n",
       "      <td>0.530379</td>\n",
       "      <td>0.072929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045305</td>\n",
       "      <td>0.041234</td>\n",
       "      <td>0.020361</td>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.062213</td>\n",
       "      <td>0.074373</td>\n",
       "      <td>0.034305</td>\n",
       "      <td>0.057444</td>\n",
       "      <td>0.046259</td>\n",
       "      <td>0.069673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>Bath</td>\n",
       "      <td>31.159452</td>\n",
       "      <td>0.765305</td>\n",
       "      <td>0.658849</td>\n",
       "      <td>0.04378</td>\n",
       "      <td>0.59818</td>\n",
       "      <td>0.35804</td>\n",
       "      <td>0.453283</td>\n",
       "      <td>0.072793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029437</td>\n",
       "      <td>0.054974</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>0.043238</td>\n",
       "      <td>0.046005</td>\n",
       "      <td>0.066493</td>\n",
       "      <td>0.039471</td>\n",
       "      <td>0.067132</td>\n",
       "      <td>0.050350</td>\n",
       "      <td>0.061944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>32.532757</td>\n",
       "      <td>0.284236</td>\n",
       "      <td>0.667442</td>\n",
       "      <td>0.05142</td>\n",
       "      <td>0.63595</td>\n",
       "      <td>0.31261</td>\n",
       "      <td>0.406191</td>\n",
       "      <td>0.077334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030151</td>\n",
       "      <td>0.053651</td>\n",
       "      <td>0.020984</td>\n",
       "      <td>0.036746</td>\n",
       "      <td>0.051528</td>\n",
       "      <td>0.098598</td>\n",
       "      <td>0.053651</td>\n",
       "      <td>0.050651</td>\n",
       "      <td>0.075720</td>\n",
       "      <td>0.059077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I</td>\n",
       "      <td>Nursery</td>\n",
       "      <td>29.706887</td>\n",
       "      <td>0.426242</td>\n",
       "      <td>0.632424</td>\n",
       "      <td>0.04873</td>\n",
       "      <td>0.63864</td>\n",
       "      <td>0.31266</td>\n",
       "      <td>0.420510</td>\n",
       "      <td>0.076763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029085</td>\n",
       "      <td>0.069240</td>\n",
       "      <td>0.020656</td>\n",
       "      <td>0.043989</td>\n",
       "      <td>0.042778</td>\n",
       "      <td>0.106477</td>\n",
       "      <td>0.039585</td>\n",
       "      <td>0.063251</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.047285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>J</td>\n",
       "      <td>Pet</td>\n",
       "      <td>32.365330</td>\n",
       "      <td>0.521686</td>\n",
       "      <td>0.627844</td>\n",
       "      <td>0.03881</td>\n",
       "      <td>0.62310</td>\n",
       "      <td>0.33813</td>\n",
       "      <td>0.498119</td>\n",
       "      <td>0.075529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040801</td>\n",
       "      <td>0.054829</td>\n",
       "      <td>0.022079</td>\n",
       "      <td>0.038181</td>\n",
       "      <td>0.044079</td>\n",
       "      <td>0.063353</td>\n",
       "      <td>0.057660</td>\n",
       "      <td>0.061912</td>\n",
       "      <td>0.046183</td>\n",
       "      <td>0.054268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  wfsku   mkcname  avgweight  returnratescaled  subjectivity      neg  \\\n",
       "0     A  Lighting  28.414403          0.593681      0.603041  0.03527   \n",
       "1     B      Rugs  36.619338          0.065961      0.671528  0.04283   \n",
       "2     C  Tabletop  33.790857          0.120171      0.650995  0.04503   \n",
       "3     D   Bedroom  32.060588          0.640660      0.596602  0.03180   \n",
       "4     E   Outdoor  25.741503          0.476572      0.634164  0.03968   \n",
       "5     F    Window  26.438588          0.835132      0.619593  0.03165   \n",
       "6     G      Bath  31.159452          0.765305      0.658849  0.04378   \n",
       "7     H   Kitchen  32.532757          0.284236      0.667442  0.05142   \n",
       "8     I   Nursery  29.706887          0.426242      0.632424  0.04873   \n",
       "9     J       Pet  32.365330          0.521686      0.627844  0.03881   \n",
       "\n",
       "       neu      pos  compound      emb1  ...  topic_10  topic_11  topic_12  \\\n",
       "0  0.66913  0.29563  0.452125  0.070353  ...  0.030215  0.055562  0.020465   \n",
       "1  0.59847  0.35869  0.443316  0.076775  ...  0.032076  0.037353  0.022174   \n",
       "2  0.62919  0.32579  0.501917  0.072777  ...  0.037819  0.032704  0.019410   \n",
       "3  0.65842  0.30977  0.453621  0.072893  ...  0.034913  0.064193  0.023080   \n",
       "4  0.62331  0.33700  0.465525  0.078262  ...  0.044107  0.042934  0.019172   \n",
       "5  0.62760  0.34071  0.530379  0.072929  ...  0.045305  0.041234  0.020361   \n",
       "6  0.59818  0.35804  0.453283  0.072793  ...  0.029437  0.054974  0.020601   \n",
       "7  0.63595  0.31261  0.406191  0.077334  ...  0.030151  0.053651  0.020984   \n",
       "8  0.63864  0.31266  0.420510  0.076763  ...  0.029085  0.069240  0.020656   \n",
       "9  0.62310  0.33813  0.498119  0.075529  ...  0.040801  0.054829  0.022079   \n",
       "\n",
       "   topic_13  topic_14  topic_15  topic_16  topic_17  topic_18  topic_19  \n",
       "0  0.028380  0.049465  0.078697  0.043955  0.053008  0.063191  0.052206  \n",
       "1  0.026493  0.050864  0.106854  0.046019  0.044543  0.056818  0.042712  \n",
       "2  0.052709  0.048334  0.079482  0.043561  0.052390  0.062868  0.056888  \n",
       "3  0.037382  0.047633  0.093049  0.045611  0.042580  0.058763  0.045817  \n",
       "4  0.056636  0.043017  0.098722  0.040517  0.051430  0.039114  0.049712  \n",
       "5  0.036111  0.062213  0.074373  0.034305  0.057444  0.046259  0.069673  \n",
       "6  0.043238  0.046005  0.066493  0.039471  0.067132  0.050350  0.061944  \n",
       "7  0.036746  0.051528  0.098598  0.053651  0.050651  0.075720  0.059077  \n",
       "8  0.043989  0.042778  0.106477  0.039585  0.063251  0.052381  0.047285  \n",
       "9  0.038181  0.044079  0.063353  0.057660  0.061912  0.046183  0.054268  \n",
       "\n",
       "[10 rows x 46 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check result\n",
    "products_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We confirm that all the extracted NLP features are now merged into the product-level data. With this augmented data, we can then build product-level models that predict product return rates.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wayfair-nlp",
   "language": "python",
   "name": "wayfair-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
